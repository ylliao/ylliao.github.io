<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>春华秋实</title>
  
  <subtitle>一份耕耘，一份收获</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://ylliao.github.io/"/>
  <updated>2018-11-27T15:36:10.231Z</updated>
  <id>http://ylliao.github.io/</id>
  
  <author>
    <name>廖月礼</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Apache Kafka实战剖析</title>
    <link href="http://ylliao.github.io/2018/11/27/Apache-Kafka%E5%AE%9E%E6%88%98%E5%89%96%E6%9E%90/"/>
    <id>http://ylliao.github.io/2018/11/27/Apache-Kafka实战剖析/</id>
    <published>2018-11-27T15:33:04.000Z</published>
    <updated>2018-11-27T15:36:10.231Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Apache-Kafka实战剖析"><a href="#Apache-Kafka实战剖析" class="headerlink" title="Apache Kafka实战剖析"></a>Apache Kafka实战剖析</h2><ol><li>Kafka安装</li></ol><p>&emsp;Kafka的官网(<a href="http://kafka.apache.org)，目前Kafka的最新版本是1.0，于2017-11-01发布的，实际上对于我们的学习来说，哪个链接的下载都是可以的。他们是根据不同的Scala版本来划分的，因为Kafka内核是由Scala语言来编写的。当然，Kafka提供了了针对不同语言的客户端。这里我们根据网站的建议，下载Scala" target="_blank" rel="noopener">http://kafka.apache.org)，目前Kafka的最新版本是1.0，于2017-11-01发布的，实际上对于我们的学习来说，哪个链接的下载都是可以的。他们是根据不同的Scala版本来划分的，因为Kafka内核是由Scala语言来编写的。当然，Kafka提供了了针对不同语言的客户端。这里我们根据网站的建议，下载Scala</a> 2.11 - kafka_2.11-1.0.0.tgz这一版本。下载完成后解压到相应的目录，由于Kafka是依赖于ZooKeeper的，通过ZooKeeper来管理理各种数据与元数据，因此还需要下载ZooKeeper。</p><p>&emsp;ZooKeeper的官网(<a href="http://zookeeper.apache.org)，下载完成后解压到相应的目录，需将config目录下的zoo_sample.cfg文件备份，然后重命名为zoo.cfg，打开zoo.cfg文件，找到文件的第12行，这是ZooKeeper存放数据的目录位置（dataDir），我们可以将其修改为自己系统上的一个已知未知，其他内容则无需修改。值得注意的是，第14行表示ZooKeeper启动时的端口号，默认值为2181，使用默认值即可。" target="_blank" rel="noopener">http://zookeeper.apache.org)，下载完成后解压到相应的目录，需将config目录下的zoo_sample.cfg文件备份，然后重命名为zoo.cfg，打开zoo.cfg文件，找到文件的第12行，这是ZooKeeper存放数据的目录位置（dataDir），我们可以将其修改为自己系统上的一个已知未知，其他内容则无需修改。值得注意的是，第14行表示ZooKeeper启动时的端口号，默认值为2181，使用默认值即可。</a></p><ol start="2"><li>启动ZooKeeper</li></ol><p>&emsp;进入到bin目录，然后运行如下命令：</p><pre><code>./zkServer.sh start-foreground</code></pre><p>&emsp;如提示权限不足，则先赋予运行该脚本的权限，执行如下命令：</p><pre><code>chmod 777 zkServer.sh</code></pre><p>&emsp;然后再运行启动ZooKeeper的命令：</p><pre><code>./zkServer.sh start-foreground</code></pre><p>&emsp;如果出现提示：operation not permitted: ./zkServer.sh，那么还需要在执行如下命令：</p><pre><code>xattr -d com.apple.quarantine zkServer.sh</code></pre><p>&emsp;接下来，再执行如下命令：</p><pre><code>./zkServer.sh start-foregroundstart-foreground：它会在前台运行ZooKeeper，当命令窗口关闭时，ZooKeeper Server相应的也会停止运行；start：它会让ZooKeeper在后台启动和运行，并不会随着命令行窗口的关闭而停止服务。</code></pre><p>&emsp;若为windows，则执行如下命令即可：</p><pre><code>zkServer.cmd</code></pre><p>&emsp;<img src="E:/ImgStore/zk.png" alt="image"></p><p>&emsp;若出现上述界面，则表示ZooKeeper启动成功。</p><ol start="3"><li>启动Kafka</li></ol><p>&emsp;进入到Kafka解压缩后的目录，执行如下命令：</p><pre><code>bin/kafka-server-start.sh config/server.properties</code></pre><p>&emsp;如果还是出现permission denied:，则进入到bin目录并执行如下命令：</p><pre><code>chmod 777 *.sh</code></pre><p>&emsp;表示赋予bin目录下所有文件的可执行权限，接下来回到bin的上层目录，执行如下命令：</p><pre><code>bin/kafka-server-start.sh config/server.properties</code></pre><p>&emsp;若为windows，则执行如下命令：</p><pre><code>kafka-server-start.bat D:\JavaTechnology\kafka_2.11-1.0.0\config\server.properties</code></pre><p>&emsp;<img src="E:/ImgStore/kfk.png" alt="image"></p><p>&emsp;若出现上述界面，则表示Kafka启动成功。</p><p>&emsp;至此为止，ZooKeeper与Kafka全部启动成功。</p><ol start="4"><li>发送和接收消息</li></ol><p>&emsp;现在我们通过Kafka的脚本，通过一个生产者向Kafka发送消息，接下来通过一个消费者来接收该消息。执行如下命令创建一个主题：</p><pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic mytest</code></pre><p>&emsp;首先启动生产者，执行如下命令：</p><pre><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic mytest</code></pre><p>&emsp;接下来，启动消费者，输入如下命令：</p><pre><code>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest --from-beginning</code></pre><p>&emsp;现在回到生产者窗口，在界面中随意输入一些字符，观察消费者窗口的输出内容，成功执行后的界面如下所示：</p><p>&emsp;<img src="E:/ImgStore/pr.png" alt="image"></p><p>&emsp;以上是在生产者窗口中输入的内容。</p><p>&emsp;<img src="E:/ImgStore/co.png" alt="image"></p><p>&emsp;以上是在消费者窗口中的输出内容。</p><ol start="5"><li>Kafka重要概念</li></ol><p>&emsp;Apache Kafka本质上是一款分布式、基于发布/订阅机制的消息系统，主要使用Scala语言开发而成的；不过在新版的Kafka中，客户端代码部分已经换成了Java语言实现。Kafka的底层实际上是非常复杂的，里面涉及到大量的模式、算法、并发处理逻辑；要想正确把握好Kafka这样一个重要的消息队列产品，对于它的一些重要且核心的概念应有一个准确的认识。其重要概念如下：</p><ul><li><p>生产者(Producer)：生产者就是生产消息的组件，它的主要工作就是源源不断的生产出消息，然后发送给消息队列。生产者可以向消息队列发送各种类型的消息，如狭义的字符串消息，也可以发送二进制消息。生产者是消息队列的数据来源，只有通过生产者持续不断地向消息队列发送消息，消息队列才能不断地处理消息。</p></li><li><p>消费者(Consumer)：消费者指的是不断消费(获取)消息的组件，它获取消息的来源就是消息队列(即Kafka本身)。换句话说，生产者不断向消息队列发送消息，而消费者不断从消息队列中获取消息。这里的消息队列(即Kafka)则充当了一个中介的角色，连接了生产者与消费者这两大功能组件。从这个意义上来说，借助于消息队列，我们实现了生产者系统与消费者系统之间的解耦，使得原来需要两个系统之间有紧密联系的状况变成了两个系统可以各自针对Kafka进行编程(只要提前约定好一些契约即可)，这可以使得生产者系统完全不需要了解消费者系统的各种信息(比如说消费者系统的地址、端口号、URL、使用的是REST接口还是RPC等等；反之亦然)。这正是消息队列所提供的另外一个绝佳好处，极大降低了系统之间的耦合度。</p></li><li><p>代理(Broker)：代理这个概念是消息队列领域中一个常见的概念，在Kafka这个领域中，Broker其实指的就是一台Kafka Server。换句话说，我们可以将部署的一台Kafka Server看作是一个Broker，就这么简单。那么从流程上来说，生产者会将消息发送给Broker，然后消费者再从Broker中拉取消息。</p></li><li><p>主题(Topic)：主题是一个逻辑上的概念，它用于从逻辑上来归类与存储消息本身。多个生产者可以向一个Topic发送消息，同时也可以有多个消费者消费一个Topic中的消息。Topic与消息这两个概念之间密切相关，Kafka中的每一条消息都会归属于某一个Topic，而一个Topic下面可以有任意数量的消息。正是由于Topic这个逻辑上的概念，Kafka将各种各样的消息进行了分门别类，使得不同的消息归属于不同的Topic，这样就可以实现不同系统的生产者可以向同一个Broker发送消息，而不同系统的消费者则可以根据Topic的名字从Broker中拉取消息。Topic是一个字符串，实际上，生产者发送消息时就指定了将消息发送给哪个Topic。在上个示例中，我们将消息发送给一个名为”mytest”的主题，而消费者在拉取消息时也指定了拉取Topic中名为”mytest”的消息。通地Topic这样一个逻辑上的概念，我们就实现了生产者与消费者之间有针对性的发送和拉取。</p></li><li><p>消息(Record)：消息是指生产者发送与消费者拉取的一个原子事物，一个消息需要关联到一个Topic上，表示该消息从属于哪个Topic。消息由一串字节所构成，其中主要由key和value两部分内容，key与value本质上都是字节数组。在发送消息时，我们可以省略掉key部分，而直接使用value部分。如上个示例中，生产者在发送消息时，发送的是：”hello world”、”welcome”、”见到你很高兴”，实际上，他们都是消息的value，即消息真正的内容本身。key的主要作用则是根据一定的策略，将此消息发送到指定的分区中，这样就可以确保包含同一个key值的消息全部都写入到同一个分区中。因此，可以得出一个结论：对于Kafka的消息来说，真正的消息内容本身是由value所承载的。为了提升消息发送的效率和存储效率，生产者会批量将消息发送给Broker，并根据相应的压缩算法在发送前对消息进行压缩。</p></li><li><p>集群(Cluster)：集群是指的是由多个Broker所共同构成的一个整体，对外提供统一的服务，这类似我们在部署系统时都会采用集群的方式来进行。借助于集群的方式，Kafka消息队列系统可以实现高可用与容错，即一台Broker挂掉了也不会影响整个消息系统的正常运行。集群中的各台Broker之间是通过心跳(Heartbeat)的方式来检测其他机器是否还存活。</p></li><li><p>控制器(Controller)：控制器是集群中的概念，每个集群中会选择出一个Broker担任控制器的角色，控制器是Kafka集群的中心。在一个Kafka集群中，除控制器这台Broker之外的其他Broker会根据控制器的调度来实现相应的功能。控制器负责管理Kafka分区的状态、管理每个分区的副本状态、监听ZooKeeper中数据的变化并作用相应的反馈等功能。此外，控制器也类似于主从的概念，所有的Broker都会监听控制器Leader的状态，当Leader控制器出现问题或故障时，则重新选择新的控制器Leader，这里涉及到一个选择算法的问题。</p></li><li><p>消费者组(Consumer Group)：消费者组与消费者之间密切相关，在Kafka中，多个消费者可以共同构成一个消费者组，而一个消费者只能从属于一个消费者组。消费者组最为重要的一个功能就是实现广播与单播的功能。一个消费者组可以确保其所订阅的Topic的每个分区只能被从属于该消费者组中的唯一一个消费者所消费；如果不同的消费者订阅了同一个Topic，那么这些消费者组之间是彼此独立的，不会受到相互的干扰。因此，如果我们希望一条消息可以被多个消费者所消费，那就可以将这些消费者放置到不同的消费者组中，这实际上就是广播的效果；如果希望一条消息只能被一个消费者所消费，那么就可以将这些消费者放置到同一个消费者组中，这实际上就是单播的效果。因此，我们可以将消费者看作是”逻辑上的订阅者”，而物理上的订阅者则是各个消费者。值得注意的是，消费者组是一个非常、非常、非常重要的概念。==很多Kafka初学者都会遇到这样一个问题：将系统以集群的形式部署(比如说部署到3台机器或是虚拟机上)，每台机器器的指定代码都是完全一样的，那么在运行时，只会有一台机器会持续不断地收到Broker中的消息，而其他机器则一条消息也收不不到。究其本质是系统部署时采用了集群部署，因此每台机器的代码与配置都是完全一样的；这样，这些机器(消费者)都从属于同一个消费者组，既然从属于同一个消费者组，那么这同一个消费者组中，只会有一个消费者会接收到消息，而其他消费者则完全接收不到任何消息，这就是单播的效果。这点要引起大家注意。==</p></li></ul><p>&emsp;对于以上这些概念的准确理解，是后续学习好Kafka框架的关键所在。</p><ol start="6"><li>主题概念应用示例</li></ol><p>&emsp;进入Kafka目录下的bin目录，执行如下命令：</p><pre><code>./kafka-topics.sh</code></pre><p>&emsp;该脚本提供了包括主题的创建、删除、查看描述、修改等行为，主题(Topic)是Kafka中一个非常重要且核心概念，它是一个逻辑上的概念，用于对消息进行逻辑分类，在发送消息与消费消息时，都需要指定向哪个主题发送，从哪个主题获取消息。如在发送消息时，所指定的主题并不存在，那么根据Kafka的配置，可能会发生以下两种情况：</p><ul><li>Kafka Server会报错，告诉发送者该主题不存在，需要先创建好主题后再发送信息；</li><li>Kafka Server会自动创建所指定的主题，并将所发送的消息归类到所创建的这个主题下面。</li></ul><p>&emsp;之所以会有以上两种区别，关键在于Kafka的配置文件中的一个参数项：</p><pre><code>auto.create.topics.enable=true</code></pre><p>&emsp;如将该参数指定为true，那么在发送消息时，如指定的主题不存在，Kafka就会帮助我们自动创建该主题；反之，则会报错。</p><p>&emsp;在命令行中执行如下命令：</p><pre><code>./kafka-topics.sh --list --zookeeper localhost:2181</code></pre><p>&emsp;输出如下所示信息：</p><pre><code>__consumer_offsetsmytest</code></pre><p>&emsp;该命令列出了两个主题，分别是<strong>consumer_offsets和mytest，其中</strong>consumer_offsets是Kafka Server所创建的用于标识消费者偏移量的主题(Kafka中的消息都是顺序保存在磁盘上的，通过offset偏移量来标识消息的顺序)，它由Kafka Server内部使用，另一个主题则是上面示例中所创建的主题：mytest。若想查看某个具体主题的详细信息，请执行台下命令：</p><pre><code>./kafka-topics.sh --describe --topic mytest --zookeeper localhost:2181</code></pre><p>&emsp;输出如下所示该主题的详细信息：</p><p>&emsp;<img src="E:/ImgStore/show.png" alt="image"></p><p>&emsp;上图中输出的第一行信息分别表示为：</p><pre><code>主题名：mytest分区数：1副本数：1</code></pre><p>&emsp;第二行信息分别表示为：</p><pre><code>主题名：mytest当前分区：0Leader Broker：0副本：0lsr(In-Sync Replica)：0</code></pre><p>&emsp;还可查看Kafka Server自己所创建的用于管理消息偏移量的主题__consumer_offsets的详细信息，执行如下命令：</p><pre><code>./kafka-topics.sh --describe --topic __consumer_offsets --zookeeper localhost:2181</code></pre><p>&emsp;输出如下信息：</p><p>&emsp;<img src="E:/ImgStore/offsets.png" alt="image"></p><p>&emsp;从上图可以看出，该主题有50个分区，1个副本，同时也输出了相应的配置信息。从第二行开始，列出了每个分区的信息，分区从0到49，由于这里使用了单台Kafka Server，因此可以看到每个分区的Leader都是0，这表示每个分区的Leader都是同一台Server，即当前启动的这台Kafka Server。</p><p>&emsp;实际上，这些主题信息都保存在ZooKeeper中的，Kafka是重度依赖于ZooKeeper的，ZooKeeper保存了Kafka所需的元信息以及关于主题、消费者偏移量等信息。</p><p>&emsp;下面查看一下ZooKeeper相关的内容，通过ZooKeeper Client连接到Server，执行如下命令：</p><pre><code>./zkCli.sh -server localhost:2181</code></pre><p>&emsp;连接成功后，会显示出命令输入界面，如下图所示：</p><p>&emsp;<img src="E:/ImgStore/cli.png" alt="image"></p><p>&emsp;ZooKeeper提供了很多客户端使用命令，可以方便地查看与操作ZooKeeper的节点信息与属性信息。执行如上命令：</p><pre><code>ls /</code></pre><p>&emsp;<img src="E:/ImgStore/ls.png" alt="image"></p><p>&emsp;还可以输入如下命令：</p><pre><code>ls2 /</code></pre><p>&emsp;上述命令除了会列出ZK根（/）下面的所有节点外，还会额外输出其他相关的信息（可以认为ls2命令是ls命令的增强版，ls2相当于ls+stat两个命令的集合体，而stat命令则是用于输出状态信息），如下图所示：</p><p>&emsp;<img src="E:/ImgStore/ls2.png" alt="image"></p><p>&emsp;下面来查询Kafka主题相关的信息，输入如下命令：</p><pre><code>ls /config/topics</code></pre><p>&emsp;它会列出路径/config/topics下的节点信息，输出如下所示：</p><p>&emsp;<img src="E:/ImgStore/lsct.png" alt="image"></p><p>&emsp;从上图可以看出，Kafka Server的两个主题信息全部被显示出来。还可以查看更多的统计信息，命令如下：</p><pre><code>ls2 /config/topics</code></pre><p>&emsp;输出结果如下图所示：</p><p>&emsp;<img src="E:/ImgStore/lsct2.png" alt="image"></p><p>&emsp;从上图可以看出，该命令不仅输出主题的名称，还输出了相关的统计信息，如创建时间，版本号等。</p><p>&emsp;本质上，ZK是一种树形结构，有一个根节点/，它下面可以有若干个子节点，子节点下面还可以有字节点，每个子节点有自己的属性等信息，其结构如下所示：</p><p>&emsp;<img src="E:/ImgStore/tree.png" alt="image"></p><p>&emsp;ZooKeeper是Kafka的得力助手，同时也是很多系统所依赖的底层协调框架，对于Zookeeper来说，有很多图形化的客户端能以比较直观的方式列出各个节点的信息。</p><ol start="7"><li>深入Kafka主题与消费者组</li></ol><p>&emsp;创建一个新主题-mytest2，命令如下：</p><pre><code>./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic mytest2</code></pre><p>&emsp;执行完后，输出如上所示：</p><pre><code>Created topic &quot;mytest2&quot;.</code></pre><p>&emsp;上述命令中的参数，需要注意的是–replication-factor与–partitions，这两个参数，前者表示主题拥有的副本数，后者表示主题拥有的分区数。上面所创建的主题mytest的副本数为1，分区数也为1。</p><p>&emsp;接下来再次执行如下命令（列出所有主题）：</p><pre><code>./kafka-topics.sh --list --zookeeper localhost:2181</code></pre><p>&emsp;执行后，控制台输出如下所示：</p><pre><code>__consumer_offsetsmytestmytest2</code></pre><p>&emsp;同上可以看出，多了一个新的主题mytest2。现在向新创建的主题mytest2发送若干条消息，执行如下命令：</p><pre><code>./kafka-console-producer.sh --broker-list localhost:9092 --topic mytest2</code></pre><p>&emsp;然后启动两个Kafka Consumer客户端，分别执行如下命令：</p><pre><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest2 --from-beginning</code></pre><p>&emsp;现在这两个Kafka Consumer都在等待mytest2主题上新消息的到来。回到刚才生产者控制台，输入字符并回车：==hello world==，此时可以发现两个Kafka Consumer均收到了该消息。再在生产者控制台输入字符并回车：==welcome==，此时可以发现两个Kafka Consumer也都收到了该消息。通过上面的操作过程，可以看到多个Kafka Consumer可以消费同一个主题的同一条消息，这就是广播概念，即多个客户端是可以获取到同一个主题的同一条消息并进行消费的。</p><p>&emsp;下面关闭这两个Kafka Consumer(ctrl + c)，然后再分别在这两个控制台执行上面同样的命令：</p><pre><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest2 --from-beginning</code></pre><p>&emsp;此时，消费者窗口中会显示出Kafka Server中mytest2主题下已经拥有的两条消息：==hello world 和 welcome==。现在再次关闭这两个Kafka Consumer，然后分别在这两控制台执行如下命令：</p><pre><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest2</code></pre><p>&emsp;可以发现这两个Kafka Consumer均不会再显示出mytest2主题下的信息。在生产者窗口输入如下字符并回车：==people==，两个Kafka Consumer均收到了该条消息。通过这个操作，可以知道–from-beginning参数的作用：++如果消费者尚没有已建立的可用于消费的偏移量，那么就从Kafka Server日志中最早的消息开始消费，而非最新的消息开始消费。++</p><p>&emsp;再次停止两个Kafka Consumer，然后分别在两个控制台输入如下命令：</p><pre><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest2 --group mygroup</code></pre><p>&emsp;现在生产者窗口输入如下字符并回车：==byebye==，发现只有一个消费者窗口收到了该条消息，而另一台Consumer则没有收到。然后再在生产者窗口继续输入如下字符并回车：==person==，结果与之前的一样，依然只有一台Consumer（而且是方才收到了byebye消息的那台）收到了该消息。现在停止刚才收到两条消息的那台Consumer，只保留一台Consumer，并在生产者窗口继续输入如下字符并回车：==beijing==，发现继续运行的这台Consumer收到了该条消息。</p><p>&emsp;上述的操作了演示了Kafka消费者组的作用。关于消费者组，上面已做过详细介绍，见5。</p><p>&emsp;现在将运行中的这台Kafka Consumer停掉，然后启动两个Kafka Consumer，分别在控制台执行如下命令：</p><pre><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest2 --group mygroup./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest2 --group mygroup2</code></pre><p>&emsp;上述命令运行在两个控制台中，区别在于消费者组名字不同，一个是mygroup，另一个是mygroup2。</p><p>&emsp;此时在生产者窗口输入如下字符并回车：==tianjin==，可以看到两个kafka Consumer均收到了该条消息。原因在于，这两个Kafka Consumer归属于不同的消费者组，因此都可以收到该条消息，即实现了广播的效果。</p><ol start="8"><li>Kafka主题删除与分区深度解析</li></ol><p>&emsp;执行查看当前Kafka Server中存在主题的命令：</p><pre><code>./kafka-topics.sh --zookeeper localhost:2181 --list</code></pre><p>&emsp;输出结果如下所示：</p><pre><code>__consumer_offsets&lt;br/&gt;mytest&lt;br/&gt;mytest2</code></pre><p>&emsp;接下来尝试删除mytest2的主题，命令如下：</p><pre><code>./kafka-topics.sh --zookeeper localhost:2181 --delete --topic mytest2 </code></pre><p>&emsp;输出结果如下所示：</p><pre><code>Topic mytest2 is marked for deletion. Note: This will have no impact if delete.topic.enable is not set to true. </code></pre><p>&emsp;以上输出表示：主题mytest2已被标记为删除状态，同时也给出了一个提示信息，即若没有将配置项delete.topic.enable设为true，那么这个删除操作将不会起任何作用。</p><p>&emsp;我们所接触到的各种配置均在Kafka Server的config目录下的server.properties配置文件中进行的。不过，我们之前并未在该文件中做过delete.topic.enable的配置。打开server.properties配置文件，看里面是否有该配置项（实际上，该文件不存在该 配置项）。</p><p>&emsp;在次执行列出全部主题命令，如下所示：</p><pre><code>./kafka-topics.sh --zookeeper localhost:2181 --list</code></pre><p>&emsp;输出如下结果：</p><pre><code>__consumer_offsetsmytest</code></pre><p>&emsp;为了更加明确该主题已经被删除，可通过以下命令查看一下mytest2主题的详细信息：</p><pre><code>./kafka-topics.sh --zookeeper localhost:2181 --describe --topic mytest2</code></pre><p>&emsp;若执行该命令后，没有任何输出，则表明主题mytest2已被删除了。回到启动Kafak Server的控制窗口，就会发现窗口输出如下日志信息：</p><p>&emsp;<img src="E:/ImgStore/delinfo.png" alt="image"></p><p>&emsp;从Kafka Server的输出日志中可以很看出，Kafka Server先是删除了与主题mytest2相关的索引信息，然后删除了日志信息，即数据文件。</p><p>&emsp;进入ZooKeeper下的bin目录，执行如下命令：</p><pre><code>./zkCli.sh</code></pre><p>&emsp;该命令会连接到Zookeeper服务端，然后再执行如下命令：</p><pre><code>ls /config/topics</code></pre><p>&emsp;输出如下所示：</p><pre><code>[mytest, __consumer_offsets]</code></pre><p>&emsp;基于以上操作与相应的输出结果，可以确定，主题mytest2及相关数据已被删除了（主题删除操作是不可逆的）。</p><p>&emsp;++在Kafka 1.0之前的版本中，delete.topic.enable属性值默认为false，若想删除主题，需要在server.properties配置文件中显示增加delete.topic.enable=true这项配置，然而，在Kafka1.0中，该配置项默认为true。因此，无需显式指定即可删除主题；如不希望删除主题，那么就需要显示将delete.topic.enable=false添加到server.properties配置文件中。另外，在Kafka 1.0之前的版本中，如果删除了主题，那么被删除的主题名字会保存到ZooKeeper的 /admin/delete_topics 节点中。虽然主题被删除了，但与主题相关的消息数据依然还会保留，需要用户手动到相关的数据目录下自行删除，然后这一切在Kafka 1.0中都发生了变化。在Kafka 1.0中，当主题被删除后，与主题相关的数据也会一并删除，并且不可逆。++</p><p>&emsp;<strong>分区：</strong>每个主题可以划分为多个分区（每个主题都至少会有一个分区，在之前的示例中，在创建主题时所使用的参数–partitions即表示所创建的主题的分区数，当时指定值为1）。在同一个主题下的不同分区包含的消息是不同的，每个消息在被添加到分区中时，都会被分配一个偏移量（offset），它是消息在所在分区中的唯一编号，kafka是通过offset来确保消息在一个分区内的顺序。offset的顺序性并不跨越分区，这意味着kafka只会确保在同一个分区内的消息是有序的，但同一个主题的多个分区内的消息，kafka并不会保证其顺序性。</p><p>&emsp;关于分区与主题之间的关系，如下图所示：</p><p>&emsp;<img src="E:/ImgStore/topic.png" alt="image"></p><p>&emsp;从上图可以看出，消息在每个分区中是有严格有序的，而不同分区之间的消息则是不保证顺序的。基于这样的设计策略，kafka的性能并不会随着分区中消息量而增多而产生损耗，因此存储较长时间的数据也不会导致什么问题。</p><p>&emsp;Kafka中的消息记录是保存在磁盘上的，通过为每个消息分配一个offset，即可以很好地确保同一分区中消息的顺序性。另外，Kafka中的消息在磁盘上是有一定的保留时间的，在这个时间内，消息会存储在磁盘上；当过了这个时间，消息即会被丢弃掉，从而释放磁盘空间。该参数位于server.properties文件中，默认为：log.retention.hours=168。即消息默认会保留7天；当然，可根据实际情况来修改该时间，修改后重启Kafka Server即可生效。</p><p>&emsp;下图展示了Kafka一个分区中消息的生产与消费情况：</p><p>&emsp;<img src="E:/ImgStore/consume.png" alt="image"> </p><p>&emsp;从上图可以看出，每个消息在同一个分区中都有唯一的一个偏移量（offset）</p><p>&emsp;分区是kafka实现高吞吐量的一个重要手段，特别是在kafka集群环境下，一个主题的消息会分布在不同的kafka server上，实现了分布式的消息存储，特别是搭配上kafka副本的配置效果更佳。</p><ol start="9"><li>深入Kafka分区与原理详解</li></ol><p>&emsp;每个分区都是一个有序、不可变的消息序列，后续新来的消息会持续不断的追加到分区的后面，这相当于一个结构化的提交日志（Git的提交日志是严格有序的）。分区中的每一条消息都会被分配一个连续的id值（即offset），该值用于唯一标识分区中的每一条消息。分区中kafka中扮演如下作用：</p><ul><li><p>分区中的消息数据是存储在日志文件中的，而同一分区中的消息数据是按照发送顺序严格有序的。分区在逻辑上对应于一个日志，当生产者将消息写入分区时，实际上是写入到了分区对应的日志中。而日志可以看作是一个逻辑上的概念，它对应于磁盘上的一个目录。一个日志由多个Segment构成，每个Segment对应于一个索引文件与一个日志文件。</p></li><li><p>借助于分区，可以实现kafka server的水平扩展。一台机器，无论是物理机还是虚拟机，运行能力是有上限的，当一个机器到达能力上限时就无法再扩展，即垂直扩展能力是受到硬件制约的。通过使用分区，可以将一个主题中的消息分散到不同的kafka server上（kafka集群），这样当机器运行能力不足时，只需要增加机器就可以了，在新的机器上创建新的分区，理论上就可以实现无限的水平扩展能力。</p></li><li><p>分区还可以实现并行处理能力，向一个主题所发送的消息会发送给该主题所拥有的不同分区中，这样消息就可以实现并行发送和处理，由多个分区来接收所发送的消息。</p></li></ul><p>&emsp;在生产部署时，都会使用kafka集群，并为主题指定相应的分区数。这里只使用一个单节点的kafka broker来演示分区的设置。下南创建一个新的主题mytest3：</p><pre><code>./kafka-topics.sh --zookeeper localhost:2181 --create --topic mytest3 --partitions 3 --replication-factor 1</code></pre><p>&emsp;执行完毕后，就创建一个新的主题mytest3，并且将其–partitions参数指定为3，表示为mytest3指定了3个分区，将–replication-factor参数设定为1，表示分区副本数量为1。启动消息发送脚本，执行如下命令：</p><pre><code>./kafka-console-producer.sh --broker-list localhost:9092 --topic mytest3</code></pre><p>&emsp;此时，控制台在待输入所要发送的消息，输入如下信息：</p><p>&emsp;<img src="E:/ImgStore/message.png" alt="image"> </p><p>&emsp;打开一个新终端，执行消费者脚本，如下所示：</p><pre><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest3 --from-beginning</code></pre><p>&emsp;执行上述命令后输出结果如下所示：</p><p>&emsp;<img src="E:/ImgStore/msgout.png" alt="image"></p><p>&emsp;从上可以看出，在消费都端所得到的消息顺序与发送者发送消息时的顺序是不一样的，原因在于分区在起作用。</p><p>&emsp;关于分区，有如下两条重要原则：</p><ul><li>同一分区内的消息保证严格有序；</li><li>不同分区的消息不保证顺序性。</li></ul><p>&emsp;<img src="E:/ImgStore/topic.png" alt="image"></p><p>&emsp;再看上面的图，右侧的Writes表示生产者向Kafka Server的主题写入消息，该主题有三个分区，因此所写的消息会分布在这3个分区中；当消费者从Kafka Server的该主题拉取消息时，由于存在3个分区，因此这3个分区的消息都会被拉取出来；又因为Kafka Server的分区间是不保证消息的顺序性的，因此就得上面的结果。</p><p>&emsp;下面查看分区中的消息的位置，打开Kafka安装目录中config目录下的server.properties配置文件，找到这一行：</p><pre><code># A comma seperated list of directories under which to store log fileslog.dirs=/tmp/kafka-logs</code></pre><p>&emsp;log.dirs配置项指定了Kafka的日志文件的存放位置，日志文件位于默认位置：/tmp/kafka-logs，进入该目录中，可以看到如下信息：</p><p>&emsp;<img src="E:/ImgStore/log.png" alt="image"></p><p>&emsp;该目录下存放的就是Kafka的各种消息数据及其它关键数据文件。</p><p>&emsp;从上图可以看到以_comsumer_offsets名字开关的目录，一共有50个，分别从0-49。该目录存放的是Kafka用于判定消费者消费偏移量的系统主题（由Kafka Server自行创建，供内部使用），该主题共有50个分区，刚好映射到0-49这50个目录。还看到mytest-0目录，mytest是之前创建的一个主题，当时创建该主题的时候所指定的分区数为1（即一个分区），这里用mytest-0来表示该分区下的数据文件。</p><p>&emsp;该目录下并不存在以mytest2开头的目录，上面已经将mytest2主题删除，相关数据文件也一并会删除，所以不再有以mytest2开头的目录。</p><p>&emsp;以mytest3开头的目录共有3个，这是刚创建mytest3主题时所指定的分区数量-3。</p><p>&emsp;在Kafka的文件存储中，如果一个主题下存在多个分区（partitions）,那么每个partition就会成为一个目录，partition的命名规则为：主题名+序号。其中第一个partition序号为0，第二个是1，第三个是2，以此类推，序号最大值为-1。</p><p>&emsp;与partition相关的另一个概念为segment（段）。一个partition是由一系列有序的，不可变的消息所构成。而一个partition中的消息数量可能非常多，因此不能将所有消息都保存在同一个文件中。类似于log4j的rolling log，当partition中的消息数量增长到一定程度后，消息文件会进行切割，新的消息会被写到一个新的文件中，当新的文件增长到一定程序后，新的消息又会被写到另一个新的文件中，以此类推，而这一个个新的数据文件就称为segment（段）。</p><p>&emsp;因此，一个partition物理上同一个或多个segment所构成，每个segment中则保存了真实的消息数据，有两点需要了解：</p><ul><li><p>每个partition都相当于一个大型文件被分配到多个大小相等的segment数据文件中，每个segment中的消息数量未必相等（这与消息大小有关，不同的消息所占据的磁盘空间不同），这个特点使得老的segment文件可以很容易就被删除，有助于提升磁盘利用效率。</p></li><li><p>每个partition只需要支持顺序读写就可以了，segment文件的生命周期是由Kafka Server的配置参数所确定的。如：server.properties文件中的log.retention.hours=168就表示7天后删除老的消息文件。</p></li></ul><p>&emsp;下面进入到mytest3-0目录中，看到4个文件，这4个文件的含义分别是：</p><ul><li>00000000000000000000.index：这是segment文件的索引文件，它与00000000000000000000.log数据文件是成对出现的，后缀.index表示这是索引文件；</li><li>00000000000000000000.log：这是segment文件是数据文件，用于存储实际的消息，该文件是二进制格式的。segment文件的命名规则是partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。没有数字则用0填充，由于这里的消息数量少，因此只有一个数据文件；</li><li>00000000000000000000.timeindex：该文件是一个基于消息日期的索引文件，主要作用是在一些根据日期或时间来寻找消息的场景下使用，此外在基于时间的日志rolling或是基于时间的日志保留策略等情况下也会使用。实际上，该文件是在Kafka的后续版本中才增加的，是期版本是没有这个文件的。它是对<em>.index文件的一个补充，**.index是基于偏移量的索引文件，而</em>.timeindex则是基于时间戳的索引文件；</li><li>leader-epoch-checkpoint：是leader的一个缓存文件。实际上，它是与Kafka的HW（Hign Water）与LEO（Log End Offset）相关的一个重要文件。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Apache-Kafka实战剖析&quot;&gt;&lt;a href=&quot;#Apache-Kafka实战剖析&quot; class=&quot;headerlink&quot; title=&quot;Apache Kafka实战剖析&quot;&gt;&lt;/a&gt;Apache Kafka实战剖析&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Kafka安装&lt;
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://ylliao.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://ylliao.github.io/2018/11/26/hello-world/"/>
    <id>http://ylliao.github.io/2018/11/26/hello-world/</id>
    <published>2018-11-26T04:52:36.414Z</published>
    <updated>2018-11-26T04:52:36.414Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
